{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Lab: Time Shifts & Multi Level Indexing\n",
    "\n",
    "This lab is designed to introduce you to working with time in a more granular way, and understanding how to build features when your data has hierarchies or panels.  \n",
    "\n",
    "Ie, when you have repeated observations for the same objects.  This is an important concept because lots of statistical methods don't explicitly account for values which might naturally be correlated with one another over time.  \n",
    "\n",
    "But lots of data **is** highly correlated over time!  \n",
    "\n",
    "By the time you're done with this lab, you'll have built 9 columns that capture a variety of information about how an observed value is changing with respect to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv('../data/stocks_panel.csv',parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Set the multi-level index so the first level is the Stock symbol itself, and the second level is the date.  Make sure the date column is sorted in ascending order.  You might have to use the `sort_index(level=0)` method to get the values straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['Stock','Date']).sort_index(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** To capture some other aspects of dates, create columns in your dataset that capture this aspect of each timestamp:\n",
    "\n",
    "  - What quarter it's in\n",
    "  - Whether or not it's the last day of the month/quarter\n",
    "  - What day it is (ie, do price changes vary by day?)\n",
    "  \n",
    "**Hint:** You don't use the `dt` attribute to get date parts from index values.  Multi indices are also a little tricky.  \n",
    "\n",
    "To get what you want, try this: `df.index.get_level_values(level=1).your_datepart_here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quarter'] = df.index.get_level_values(level=1).quarter\n",
    "df['Day'] = df.index.get_level_values(level=1).day\n",
    "df['Quarter End'] = df.index.get_level_values(level=1).is_quarter_end\n",
    "df['Month End'] = df.index.get_level_values(level=1).is_month_end\n",
    "df['Daily % Change']=df.groupby(level=0)['Price'].diff()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Time Series Embedding\n",
    "\n",
    "Lots of times if you're trying to predict the value of something tomorrow, the most import piece of information is what the value of something is today, and yesterday, and so on.\n",
    "\n",
    "Try and create columns that capture previously observed values for each stock.  \n",
    "\n",
    "Make two columns that capture the value of the following:\n",
    "\n",
    " - What the previous recorded price for each stock was\n",
    " - The stock price from two observations ago\n",
    " \n",
    "**Remember:** This has to be done on a particular level of the index to make sure it's getting applied appropriately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Price Yesterday']=df.groupby(level=0)['Price'].shift(1)\n",
    "\n",
    "df['Price Two Days Ago']=df.groupby(level=0)['Price'].shift(2) \n",
    "#getting around the fact that shift has no levels argument\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals=df.groupby(level=0)['Price'].shift().reset_index()\n",
    "vals[vals.stock == 'MSFT']\n",
    "vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** How did each stock price change compared to the S&P 500? \n",
    "\n",
    "Lots of times it's useful to see how something else moves with some other item that you're trying to track.  \n",
    "\n",
    "In the data folder is a file called `s&p.csv`, and it contains the price history of the S&P 500 index for each day since its inception. See if you can upload it, and merge the `adj close` column into your dataset, so there's a column that displays the observed value of the index for every single price observation we have in our dataset.\n",
    "\n",
    "**Hints:**\n",
    " - Merging on multi-level indices is tricky and prone to failure.  To make this a little bit easier, just use `reset_index()` to pop out the date column in the multi-index, and merge on it as if it were a regular column.\n",
    " - Make sure both date columns are actually encoded as dates, rather than strings, or else the merge won't work.\n",
    " - You'll want to go back to the multi-level index when you're done with this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp=pd.read_csv('../data/s&p.csv',parse_dates=['Date'])\n",
    "df.reset_index()\n",
    "sp_adj= sp[['Date','Adj Close']]\n",
    "df.merge(sp_adj, how=\"left\", on=\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Window Statistics\n",
    "\n",
    "Lots of times, if we want to capture some idea of momentum, or how some value changes with what's usually observed.\n",
    "\n",
    "Ie, if we had 48 purchases in a store today, how does that number compare to what's happened in the last 14 days?  Are things trending up or trending down?  \n",
    "\n",
    "This also allows us to get a clearer picture of general trends in values, even if there are irregular daily spikes.\n",
    "\n",
    "To handle these sorts of issues, pandas has an entire section to calculate window statistics called `rolling`, it works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll create a sample dataframe with 30 days worth of values\n",
    "import numpy as np\n",
    "index = pd.date_range(start='01/01/2020', end='02/05/2020')\n",
    "sample_df = pd.DataFrame(np.random.randn(36), index=index, columns=['Value'])\n",
    "# and here's what it looks like\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we'll see rolling 10 day averages\n",
    "sample_df.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the number of observations to calculate, and choose your aggregator -- `mean()`, `min()`, `sum()`, etc, although `mean()` is the most common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Calculate the rolling 5 & 10 day moving averages for each stock inside the dataset.\n",
    "\n",
    "**Note:** Do *not* try and merge them back into your dataset yet, just make sure you have the values showing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupby(level=0)['price'].rolling(5).mean().values\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at the index, you should notice that it has *three* levels to it, and not just two like before.  \n",
    "\n",
    "Combining datasets with differing numbers of levels is cumbersome, and there's a decent amount of churn in what methods work from one version of Pandas to another.  \n",
    "\n",
    "For now, try and get these values back into your original dataset by taking the following steps:\n",
    "\n",
    " - calculate the 5 & 10 rolling averages for each stock price on the multilevel index, and save these as variables, and then use the *values* attribute for each one to drop the index and just get the column values (ask me about this if you have questions)\n",
    " - use reset_index() to unstack the index on your original dataframe\n",
    " - create new columns for the 5 & 10 day moving averages in the original dataset, using the values from the first step.\n",
    " \n",
    "So as a quick example, it would sort of work like this:\n",
    "\n",
    "`five_day = df.groupby(level=0)['Price'].your_stuff_here.values`\n",
    "\n",
    "And then use this as the basis to make your new column from your original dataframe with the reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
